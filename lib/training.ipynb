{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "from dataclasses import dataclass\n",
    "import torch as t\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Tuple, List, Optional, Dict, Callable\n",
    "from transformers.models.gpt2.tokenization_gpt2_fast import GPT2TokenizerFast\n",
    "from jaxtyping import Float, Int\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "\n",
    "MODEL_NAME = 'distilgpt2'\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (Tensor): A tensor of shape (batch_size, seq_len) containing token ids.\n",
    "            labels (Tensor): A tensor of shape (batch_size, seq_len) containing label token ids.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return item, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "initial_prompt = 'test'\n",
    "\n",
    "def generate_text_data() -> Tuple[] \n",
    "# returns a tuple of lists of strings: (training text data, labels = 0s, 1s)\n",
    "    pass\n",
    "\n",
    "text_data, text_labels = generate_text_data()\n",
    "\n",
    "data_token_ids = tokenizer(text_data, return_tensors=\"pt\", padding=True)['input_ids'].to(device)\n",
    "labels_token_ids = tokenizer(text_data, return_tensors=\"pt\", padding=True)['input_ids'].to(device)\n",
    "\n",
    "# create dataset and dataloader\n",
    "batch_size = 5\n",
    "token_dataset = TokenDataset(data_token_ids, labels_token_ids)\n",
    "dataloader = DataLoader(token_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_full_base_prompts(initial_prompt, data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat initial model cache maybe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (data, labels) in enumerate(dataloader):\n",
    "    base_prompt_tokens = create_full_base_prompts(initial_prompt, data)\n",
    "\n",
    "    cache = model(base_prompt_tokens, use_cache=True).past_key_values\n",
    "\n",
    "    #TODO randomize order or data,labels\n",
    "    for last_token, label in zip(data, labels):\n",
    "        outputs = model(last_token, cache)\n",
    "        logits = outputs.logits[:,:,-1,:].squeeze()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arena_w1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
