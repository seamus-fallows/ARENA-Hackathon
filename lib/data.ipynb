{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch.nn import functional as F\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.models.llama.modeling_llama import LlamaForCausalLM \n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Union, Optional, Tuple, Any\n",
    "from torch import Tensor\n",
    "from dataclasses import dataclass, field\n",
    "from tqdm.notebook import tqdm\n",
    "from jaxtyping import Int, Float\n",
    "from typing import List, Dict\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import datetime\n",
    "llama_token = \"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\"\n",
    "device = t.device(\"cuda:0\" if t.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.cuda.empty_cache()\n",
    "n_param = 7\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "            f\"meta-llama/Llama-2-{n_param}b-chat-hf\", ignore_mismatched_sizes=True, token=llama_token, use_fast=True, add_bos_token=False, add_prefix_space=False, add_special_tokens=False\n",
    "        )\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False,  True,  True, False,  True,  True,  True,  True],\n",
      "        [ True, False, False, False,  True,  True, False,  True,  True, False],\n",
      "        [ True,  True,  True, False,  True,  True,  True, False,  True, False],\n",
      "        [False, False,  True,  True,  True, False, False, False, False,  True],\n",
      "        [ True,  True, False,  True,  True, False, False,  True,  True, False],\n",
      "        [False,  True, False,  True, False,  True,  True, False,  True, False],\n",
      "        [ True,  True,  True,  True, False,  True, False, False, False, False],\n",
      "        [False,  True, False, False, False,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True, False, False, False, False,  True, False],\n",
      "        [False, False, False, False, False,  True, False,  True,  True,  True]])\n",
      "tensor([[23704, 22557,  7613, 29955, 29947,  1300, 29953, 29896, 29929, 29946],\n",
      "        [29953, 29683, 27069,  7372, 29929, 29947, 31914, 29955, 29953, 27720],\n",
      "        [29945, 29929, 29945, 25026, 29896, 29953, 29900,  2347, 29906, 29264],\n",
      "        [ 7468, 16963, 29945, 29947, 29945,  6284, 27529,  7769, 29678, 29941],\n",
      "        [29946, 29900, 26562, 29947, 29947,  3230, 23321, 29941, 29941, 13148],\n",
      "        [30263, 29945, 25192, 29906,  5839, 29955, 29941, 19012, 29896,  4547],\n",
      "        [29947, 29945, 29941, 29896,  8973, 29906, 18365, 13112,  2461, 19941],\n",
      "        [ 8406, 29941, 22854, 26187, 27160, 29955, 27078, 11392, 31968,  2874],\n",
      "        [29906, 29941, 29946, 29941, 29210, 26234, 25905, 17515, 29900, 16420],\n",
      "        [ 7453,  9134,  7412, 12961, 17341, 29955, 20455, 29929, 29946, 29900]])\n",
      "periods Engineering board78aut6194\n",
      "6nachherit пол98兴76нец\n",
      "595 Données160ived2getting\n",
      "aiJavaScript585 properly Medicine orient pelos3\n",
      "40 Asp88 Brit луч33layer\n",
      "µ5 ela2 pick73 prepare1 introdu\n",
      "8531 court2 sought believedoint Left\n",
      "Bus3spaces kisinterno7iconsęd丁 design\n",
      "2343 Николай Clayonneur gained0 confidence\n",
      "tons Both Playigned худож7Cert940\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "def generate_data_tokens(n_data: int, seq_len: int, n_numeral_per_seq: int) -> Tuple[Tensor]:\n",
    "    vocab_size = tokenizer.vocab_size\n",
    "    numeral_tokens = tokenizer.batch_encode_plus([str(i) for i in range(10)], return_tensors='pt')['input_ids'][:,1].flatten()  \n",
    "    \n",
    "    # Create a boolean mask for the entire vocabulary\n",
    "    mask = t.ones(vocab_size, dtype=t.bool)\n",
    "    mask[numeral_tokens] = 0\n",
    "\n",
    "    # Find the indices where mask is True\n",
    "    available_tokens = t.nonzero(mask).squeeze()\n",
    "\n",
    "    # Randomly choose numeral tokens \n",
    "    random_numeral_indices = t.randint(0, numeral_tokens.shape[0], (n_data, seq_len))\n",
    "    numerals_tensor = numeral_tokens[random_numeral_indices]\n",
    "\n",
    "    # Randomly choose non-numeral tokens\n",
    "    random_vocab_indices = t.randint(0, available_tokens.shape[0], (n_data, seq_len))\n",
    "    random_text_tokens = available_tokens[random_vocab_indices]\n",
    "\n",
    "    # Create a mask for the numeral tokens\n",
    "    numeral_probs = t.rand(n_data, seq_len, dtype=t.float)\n",
    "    numeral_mask = (numeral_probs < 0.5)\n",
    "\n",
    "    data = random_text_tokens\n",
    "    data[numeral_mask] = numerals_tensor[numeral_mask]\n",
    "    return data, numeral_mask\n",
    "\n",
    "data_token_ids, labels = generate_data_tokens(n_data = 10, seq_len = 10, n_numeral_per_seq = 2)\n",
    "print(labels)\n",
    "print(data_token_ids)\n",
    "\n",
    "for i in range(data_token_ids.size(0)):\n",
    "    sequence = data_token_ids[i].tolist()  # Convert the tensor to a list of integers\n",
    "    decoded_sequence = tokenizer.decode(sequence)  # Decode the sequence\n",
    "    print(decoded_sequence)  # Print the decoded text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[29871, 29900]])\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "numeral_tokens = tokenizer.batch_encode_plus([str(0)], return_tensors='pt')['input_ids']\n",
    "print(numeral_tokens)\n",
    "for id in numeral_tokens:\n",
    "    print(tokenizer.decode(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29900, 29896, 29906, 29941, 29946, 29945, 29953, 29955, 29947, 29929]\n"
     ]
    }
   ],
   "source": [
    "numeral_tokens = tokenizer.encode(\"\".join(str(i) for i in range(10)))[1:]\n",
    "print(numeral_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arena_w1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
